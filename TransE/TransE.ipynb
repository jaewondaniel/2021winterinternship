{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransE",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install dgl-cu111 -f https://data.dgl.ai/wheels/repo.html"
      ],
      "metadata": {
        "id": "04wtC45f6pFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bddc5fc-cbb0-4a5b-b1d2-f77048f305a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl-cu111\n",
            "  Downloading https://data.dgl.ai/wheels/dgl_cu111-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (165.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 165.0 MB 35 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (1.24.3)\n",
            "Installing collected packages: dgl-cu111\n",
            "Successfully installed dgl-cu111-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "dIPqtpI-UEQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad838a1-9775-42e6-9a2c-2802cbafd09c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_tensor = torch.Tensor([0,1])\n",
        "\n",
        "# https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.device\n",
        "# 어느 장치(cpu 혹은 gpu)에 텐서를 올릴지 지정합니다.\n",
        "# 아래는 torch.device라는 함수를 사용해 gpu로 장치를 지정합니다. \n",
        "device = torch.device('cuda')\n",
        "\n",
        "# https://pytorch.org/docs/stable/cuda.html?highlight=available#torch.cuda.is_available\n",
        "# gpu가 사용 가능한지 확인해줍니다.\n",
        "if torch.cuda.is_available():\n",
        "  \n",
        "  # https://pytorch.org/docs/stable/tensors.html?highlight=#torch.Tensor.to\n",
        "  # cpu에 있었던 텐서를 to 함수를 이용해 지정해놓은 장치(여기서는 gpu)로 올려줍니다.\n",
        "  gpu_tensor = cpu_tensor.to(device)\n",
        "  print(gpu_tensor)\n",
        "\n",
        "\n",
        "# to(device) 붙이면 gpu 연산 가능"
      ],
      "metadata": {
        "id": "hHfnbUebT80C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f426f102-1c83-42ae-b233-a0db6709441b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oHBoEiB62jF9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data load\n",
        "\n",
        "import dgl\n",
        "from dgl.data import FB15kDataset\n",
        "import torch\n",
        "\n",
        "dataset = FB15kDataset()\n",
        "graph = dataset[0]\n",
        "\n",
        "# edata = returns a dict[str, Tensor]\n",
        "\n",
        "train_mask = graph.edata['train_mask']\n",
        "val_mask = graph.edata['val_mask']\n",
        "test_mask = graph.edata['test_mask']\n",
        "\n",
        "head, tail = graph.edges('uv')\n",
        "rel = graph.edata['etype']\n",
        "triplet = torch.stack([head, rel, tail], dim=1)\n",
        "\n",
        "train = triplet[train_mask]\n",
        "val = triplet[val_mask]\n",
        "test = triplet[test_mask]"
      ],
      "metadata": {
        "id": "tmhsrxhA2koc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97517ee-6fbf-4e3e-bd58-e0d994f86dfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/FB15k.tgz from https://data.dgl.ai/dataset/FB15k.tgz...\n",
            "Extracting file to /root/.dgl/FB15k\n",
            "# entities: 14951\n",
            "# relations: 1345\n",
            "# training edges: 483142\n",
            "# validation edges: 50000\n",
            "# testing edges: 59071\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "YpjJIcTfNh1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransE(nn.Module):\n",
        "\n",
        "  def __init__(self,num_entity, num_rel ,embed_dim):\n",
        "    super(TransE, self).__init__()\n",
        "\n",
        "    bound = 6 / (embed_dim ** 0.5)\n",
        "\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "    # entity initialize\n",
        "    self.entity_embed = nn.Embedding(num_entity, embed_dim)\n",
        "    self.entity_embed.weight.data = torch.nn.init.uniform_(self.entity_embed.weight.data, a= - bound, b= bound)\n",
        "    self.entity_embed.weight.data = F.normalize(self.entity_embed.weight.data,p=2.0, dim=1, eps=1e-12)\n",
        "\n",
        "    # relation initialize\n",
        "    self.rel_embed = nn.Embedding(num_rel, embed_dim)\n",
        "    self.rel_embed.weight.data = torch.nn.init.uniform_(self.rel_embed.weight.data, a= - bound, b= bound)\n",
        "    self.rel_embed.weight.data = F.normalize(self.rel_embed.weight.data,p=2.0, dim=1, eps=1e-12)\n",
        "    \n",
        "    \n",
        "  def forward(self, batch, c_batch): # c_batch = corrupted batch\n",
        "    batch = batch.to(device)\n",
        "    c_batch = c_batch.to(device)\n",
        "    \n",
        "    head, rel, tail = batch[0], batch[1], batch[2]\n",
        "    c_head, c_tail = c_batch[0], c_batch[2] # c_ = corrupted\n",
        "\n",
        "    # positive sample\n",
        "    h = self.entity_embed(head).to(device)\n",
        "    r = self.rel_embed(rel).to(device)\n",
        "    t = self.entity_embed(tail).to(device)\n",
        "\n",
        "    # negative (= corrupted) sample\n",
        "    c_h = self.entity_embed(c_head).to(device)\n",
        "    c_t = self.entity_embed(c_tail).to(device)\n",
        "\n",
        "    # L1_dist: np.abs(real-pred) / L2_dist = (real-pred)**2\n",
        "    # use L1_dist\n",
        "    pos_dist = torch.norm(h+r - t, 2, dim = 0).to(device)\n",
        "    neg_dist = torch.norm(c_h+r - c_t, 2, dim = 0).to(device)\n",
        "    \n",
        "    return pos_dist, neg_dist"
      ],
      "metadata": {
        "id": "45Hi2LXNZb46"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main"
      ],
      "metadata": {
        "id": "ypl7D4VjNd2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# sampling corrupt function\n",
        "\n",
        "def sampling_corrupt(sample):\n",
        "  \n",
        "  temp_sample = sample.clone().detach() # not change original sample data\n",
        "\n",
        "  if random.random() > 0.5:\n",
        "\n",
        "    while(1):\n",
        "      \n",
        "      corrupt_head = random.choice(head)\n",
        "      if sample[0] != corrupt_head:\n",
        "        temp_sample[0] = corrupt_head\n",
        "        return temp_sample\n",
        "        break\n",
        "      \n",
        "  else:\n",
        "    while(1):\n",
        "      corrupt_tail = random.choice(tail)\n",
        "      if sample[2] != corrupt_tail:\n",
        "        temp_sample[2] = corrupt_tail\n",
        "        return temp_sample\n",
        "        break\n",
        "\n",
        "entity = graph.nodes()\n",
        "\n",
        "model = TransE(num_entity = len(entity), num_rel = len(rel), embed_dim = 50)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# for mini-batch sampling\n",
        "from torch.utils.data import DataLoader\n",
        "batch_size = 4800\n",
        "\n",
        "s_batch = DataLoader(\n",
        "    train,\n",
        "    batch_size = batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "\n",
        "  for batch_idx, s in enumerate(s_batch):\n",
        "      start = time.time()\n",
        "      s.to(device)\n",
        "\n",
        "      # sample corrupted triplets\n",
        "      corrupeted_sample = 0\n",
        "      corrupted_batch = []\n",
        "\n",
        "      temp_start = time.time()\n",
        "     \n",
        "      for i in range(len(s)):\n",
        "        corrupted_sample = sampling_corrupt(s[i])\n",
        "        corrupted_batch.append(corrupted_sample)\n",
        "\n",
        "      temp_end = time.time()\n",
        "\n",
        "      print(f\"corrupted_time1: {temp_end - temp_start}\")\n",
        "\n",
        "      # reshape for triplet form\n",
        "      corrupted_batch = torch.stack(corrupted_batch)\n",
        "      corrupted_batch = corrupted_batch.reshape(-1,3)\n",
        "      corrupted_batch.to(device)\n",
        "      \n",
        "      pos_dist_group = []\n",
        "      neg_dist_group = []\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      temp_start = time.time()\n",
        "\n",
        "      for i in range(len(s)):\n",
        "        pos_dist, neg_dist = model(s[i], corrupted_batch[i])\n",
        "        pos_dist_group.append(pos_dist)\n",
        "        neg_dist_group.append(neg_dist)\n",
        "\n",
        "      pos_dist_group = torch.stack(pos_dist_group)\n",
        "      neg_dist_group = torch.stack(neg_dist_group)\n",
        "\n",
        "      temp_end = time.time()\n",
        "\n",
        "      print(f\"corrupted_time2: {temp_end - temp_start}\")\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss_func = nn.MarginRankingLoss() # margin rank = max(0,−y∗(x1−x2)+margin)\n",
        "      loss = loss_func(pos_dist_group, neg_dist_group,torch.ones_like(pos_dist_group)*-1)\n",
        "\n",
        "      # optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      end = time.time()\n",
        "      collapsed = end - start\n",
        "      print(f\"collapsed time: {collapsed}\")\n",
        "      print(f\"Epoch {epoch}/{epochs}, Batch {batch_idx}/{len(s_batch)}, Loss: {loss}\")\n",
        "  \n",
        "\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oKpznA53_p9j",
        "outputId": "748e3b92-14b9-42be-eee7-ef51967c4c89"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corrupted_time1: 0.15424180030822754\n",
            "corrupted_time2: 2.501085042953491\n",
            "collapsed time: 32.53161311149597\n",
            "Epoch 0/10, Batch 0/202, Loss: 0.06769721210002899\n",
            "corrupted_time1: 0.12730097770690918\n",
            "corrupted_time2: 2.549299716949463\n",
            "collapsed time: 32.51039719581604\n",
            "Epoch 0/10, Batch 1/202, Loss: 0.06652938574552536\n",
            "corrupted_time1: 0.11850595474243164\n",
            "corrupted_time2: 2.355836868286133\n",
            "collapsed time: 32.308027029037476\n",
            "Epoch 0/10, Batch 2/202, Loss: 0.06369493901729584\n",
            "corrupted_time1: 0.12978053092956543\n",
            "corrupted_time2: 2.460922956466675\n",
            "collapsed time: 32.444334268569946\n",
            "Epoch 0/10, Batch 3/202, Loss: 0.06604386121034622\n",
            "corrupted_time1: 0.11590695381164551\n",
            "corrupted_time2: 2.565077066421509\n",
            "collapsed time: 32.48533535003662\n",
            "Epoch 0/10, Batch 4/202, Loss: 0.06547918170690536\n",
            "corrupted_time1: 0.1194760799407959\n",
            "corrupted_time2: 2.382580518722534\n",
            "collapsed time: 32.34035801887512\n",
            "Epoch 0/10, Batch 5/202, Loss: 0.06256358325481415\n",
            "corrupted_time1: 0.1176609992980957\n",
            "corrupted_time2: 2.331206798553467\n",
            "collapsed time: 32.25353002548218\n",
            "Epoch 0/10, Batch 6/202, Loss: 0.06489383429288864\n",
            "corrupted_time1: 0.12194442749023438\n",
            "corrupted_time2: 2.567992687225342\n",
            "collapsed time: 32.49789834022522\n",
            "Epoch 0/10, Batch 7/202, Loss: 0.06689336150884628\n",
            "corrupted_time1: 0.13071250915527344\n",
            "corrupted_time2: 2.4319145679473877\n",
            "collapsed time: 32.361594676971436\n",
            "Epoch 0/10, Batch 8/202, Loss: 0.06537839770317078\n",
            "corrupted_time1: 0.21413207054138184\n",
            "corrupted_time2: 2.4767582416534424\n",
            "collapsed time: 32.546082496643066\n",
            "Epoch 0/10, Batch 9/202, Loss: 0.0665150061249733\n",
            "corrupted_time1: 0.12012743949890137\n",
            "corrupted_time2: 2.5039799213409424\n",
            "collapsed time: 32.43443846702576\n",
            "Epoch 0/10, Batch 10/202, Loss: 0.06560458242893219\n",
            "corrupted_time1: 0.11781740188598633\n",
            "corrupted_time2: 2.356839418411255\n",
            "collapsed time: 32.27877736091614\n",
            "Epoch 0/10, Batch 11/202, Loss: 0.06549657136201859\n",
            "corrupted_time1: 0.12980294227600098\n",
            "corrupted_time2: 2.5512728691101074\n",
            "collapsed time: 32.523266077041626\n",
            "Epoch 0/10, Batch 12/202, Loss: 0.06742531061172485\n",
            "corrupted_time1: 0.11750960350036621\n",
            "corrupted_time2: 2.5768773555755615\n",
            "collapsed time: 32.50125479698181\n",
            "Epoch 0/10, Batch 13/202, Loss: 0.06701317429542542\n",
            "corrupted_time1: 0.11683773994445801\n",
            "corrupted_time2: 2.408038377761841\n",
            "collapsed time: 32.400474071502686\n",
            "Epoch 0/10, Batch 14/202, Loss: 0.06556044518947601\n",
            "corrupted_time1: 0.11719036102294922\n",
            "corrupted_time2: 2.4835686683654785\n",
            "collapsed time: 32.4093656539917\n",
            "Epoch 0/10, Batch 15/202, Loss: 0.06449676305055618\n",
            "corrupted_time1: 0.12848591804504395\n",
            "corrupted_time2: 2.565941095352173\n",
            "collapsed time: 32.53846859931946\n",
            "Epoch 0/10, Batch 16/202, Loss: 0.0671348050236702\n",
            "corrupted_time1: 0.14074468612670898\n",
            "corrupted_time2: 2.470747947692871\n",
            "collapsed time: 32.41935610771179\n",
            "Epoch 0/10, Batch 17/202, Loss: 0.06461513787508011\n",
            "corrupted_time1: 0.13849806785583496\n",
            "corrupted_time2: 2.395336151123047\n",
            "collapsed time: 32.36931109428406\n",
            "Epoch 0/10, Batch 18/202, Loss: 0.06520579755306244\n",
            "corrupted_time1: 0.1288280487060547\n",
            "corrupted_time2: 2.4383935928344727\n",
            "collapsed time: 32.373393058776855\n",
            "Epoch 0/10, Batch 19/202, Loss: 0.06718631833791733\n",
            "corrupted_time1: 0.1343364715576172\n",
            "corrupted_time2: 2.51936674118042\n",
            "collapsed time: 32.49499559402466\n",
            "Epoch 0/10, Batch 20/202, Loss: 0.06596215814352036\n",
            "corrupted_time1: 0.13380813598632812\n",
            "corrupted_time2: 2.567445755004883\n",
            "collapsed time: 32.50432109832764\n",
            "Epoch 0/10, Batch 21/202, Loss: 0.06354989856481552\n",
            "corrupted_time1: 0.12662792205810547\n",
            "corrupted_time2: 2.627418041229248\n",
            "collapsed time: 32.563533782958984\n",
            "Epoch 0/10, Batch 22/202, Loss: 0.06558560580015182\n",
            "corrupted_time1: 0.11711859703063965\n",
            "corrupted_time2: 2.3418264389038086\n",
            "collapsed time: 32.26125359535217\n",
            "Epoch 0/10, Batch 23/202, Loss: 0.06545352190732956\n",
            "corrupted_time1: 0.11905670166015625\n",
            "corrupted_time2: 2.6208016872406006\n",
            "collapsed time: 32.596014976501465\n",
            "Epoch 0/10, Batch 24/202, Loss: 0.06560267508029938\n",
            "corrupted_time1: 0.12556242942810059\n",
            "corrupted_time2: 2.547196626663208\n",
            "collapsed time: 32.47664403915405\n",
            "Epoch 0/10, Batch 25/202, Loss: 0.0653524249792099\n",
            "corrupted_time1: 0.1278243064880371\n",
            "corrupted_time2: 2.480943202972412\n",
            "collapsed time: 32.45491671562195\n",
            "Epoch 0/10, Batch 26/202, Loss: 0.06547825783491135\n",
            "corrupted_time1: 0.12145614624023438\n",
            "corrupted_time2: 2.5477583408355713\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-382cf582ace2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       \u001b[0;31m# optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "수정과정"
      ],
      "metadata": {
        "id": "v2jrJ0KIC-y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = []\n",
        "len(a)"
      ],
      "metadata": {
        "id": "06qkLDXBzBhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "# input1 = torch.Tensor([[1,2,3],[7,8,9]])\n",
        "# input2 = torch.Tensor([[4,5,6],[10,11,12]])\n",
        "\n",
        "input1 = torch.Tensor([1,2,3])\n",
        "input2 = torch.Tensor([[4,5,6]])\n",
        "\n",
        "print(input1)\n",
        "\n",
        "input1 = [np.array(input1)]\n",
        "\n",
        "print(input1)\n",
        "\n",
        "input1 = torch.Tensor(input1)\n",
        "print(input1)\n",
        "output.append(input1)\n",
        "output.append(input2)\n",
        "\n",
        "print(output)\n",
        "\n",
        "result = torch.cat(output, dim=0)\n",
        "print(result)\n",
        "\n",
        "# for ch in range(in_channels):\n",
        "#     tensor = my_fn(input_batch[:,ch,:,:])   #transform from (64, 1, 224, 224) to (64, 32, 224, 224)\n",
        "#     outputs.append(tensor)\n",
        "# result = torch.cat(outputs, dim=1)  #shape (64, 32*in_channels, 224, 224"
      ],
      "metadata": {
        "id": "SZyY51IebrG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [torch.Tensor([0]),torch.Tensor([1]),torch.Tensor([3])]\n",
        "b = torch.stack(a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "KfK23hEHLNVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.numel(torch.Tensor([0]))"
      ],
      "metadata": {
        "id": "UJxZjWZzJuI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for corrupt sample\n",
        "k = 0\n",
        "\n",
        "for batch_idx, s in enumerate(s_batch):\n",
        "  \n",
        "    corrupted = torch.Tensor([0])\n",
        "    # sample corrupted triplets\n",
        "    corrupt_sample = 0\n",
        "    print(f\"우씨: {s}\")\n",
        "\n",
        "    for i in range(len(s)):\n",
        "      corrupt_sample = sampling_corrupt(s[i])\n",
        "      if torch.numel(corrupted) == 1: #corrupted = tensor([0])\n",
        "        corrupted = corrupt_sample\n",
        "      else:\n",
        "        corrupted = torch.cat((corrupted, corrupt_sample))\n",
        "      corrupted = corrupted.reshape(-1,3)\n",
        "      print(f\"아으: {corrupted}\")\n",
        "    \n",
        "    print(f\"완성: {corrupted}\")\n",
        "\n",
        "    k += 1 # for test\n",
        "    if k > 5:\n",
        "      break"
      ],
      "metadata": {
        "id": "E97kZWoaDzcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for corrupt sample\n",
        "k = 0\n",
        "\n",
        "for batch_idx, s in enumerate(s_batch):\n",
        "  \n",
        "    temp_list = []\n",
        "    corrupted = torch.Tensor([0])\n",
        "    # sample corrupted triplets\n",
        "    corrupt_sample = 0\n",
        "    # print(f\"우씨: {s}\")\n",
        "\n",
        "    for i in range(len(s)):\n",
        "      corrupt_sample = sampling_corrupt(s[i])\n",
        "      corrupted = corrupt_sample\n",
        "      temp_list.append(corrupted)\n",
        "      \n",
        "\n",
        "      # print(f\"아으: {corrupted}\")\n",
        "    \n",
        "    # print(f\"완성: {corrupted}\")\n",
        "    print(temp_list)\n",
        "    output = torch.cat(temp_list, dim = 0)\n",
        "    print(output)\n",
        "    k += 1 # for test\n",
        "    if k > 5:\n",
        "      break"
      ],
      "metadata": {
        "id": "NlG4XsdegOJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "WV7wmrT9EDzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.arange(10).float()\n",
        "b = torch.arange(1, 11).float()"
      ],
      "metadata": {
        "id": "nXPt3RzjS3qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad = True\n",
        "b.requires_grad = True"
      ],
      "metadata": {
        "id": "xOdwyCNZS7C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # embedding initialize & normalization function\n",
        "\n",
        "# def uniform_initialize(val, bound):\n",
        "#       val = torch.nn.init.uniform_(torch.empty(val.shape), a= - bound, b= bound)\n",
        "#       return val\n",
        "\n",
        "# def normalization(val):\n",
        "#   temp_val = torch.Tensor([0])\n",
        "#   for v in val:\n",
        "#     norm_v = torch.Tensor([torch.norm(v)])\n",
        "#     temp_val = torch.cat((temp_val,norm_v))\n",
        "\n",
        "#   val = temp_val[1:] # 초기화 한 값 제거\n",
        "#   return val"
      ],
      "metadata": {
        "id": "oQvgdzUobpYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling corrupt function\n",
        "\n",
        "def sampling_corrupt(sample):\n",
        "  \n",
        "  temp_sample = sample.clone().detach() # not change original sample data\n",
        "\n",
        "  if random.random() > 0.5:\n",
        "\n",
        "    while(1):\n",
        "      \n",
        "      corrupt_head = random.choice(head)\n",
        "      if sample[0] != corrupt_head:\n",
        "        temp_sample[0] = corrupt_head\n",
        "        return temp_sample\n",
        "        break\n",
        "      \n",
        "  else:\n",
        "    while(1):\n",
        "      corrupt_tail = random.choice(tail)\n",
        "      if sample[2] != corrupt_tail:\n",
        "        temp_sample[2] = corrupt_tail\n",
        "        return temp_sample\n",
        "        break"
      ],
      "metadata": {
        "id": "9MmU20QhFntr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 시간이 너무 오래걸림, 모르는 함수가 있는건가 ?!\n",
        "\n",
        "# # relation set uniform으로 초기화 및 정규화, entity 초기화\n",
        "\n",
        "# k = 50 # embedding dimension\n",
        "\n",
        "# bound = 6/np.sqrt(k)\n",
        "\n",
        "# entity = graph.nodes()\n",
        "\n",
        "# # initialization rel, entity\n",
        "\n",
        "# rel_norm = uniform_initialize(rel, bound)\n",
        "# entity_norm = uniform_initialize(entity, bound)\n",
        "\n",
        "# # relation & entity normalization\n",
        "\n",
        "# rel_norm = normalization(rel_norm)\n",
        "# entity_norm = normalization(entity_norm)"
      ],
      "metadata": {
        "id": "7gaKuyLH2k6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def margin_loss(pos_dist, neg_dist):\n",
        "  \n",
        "  loss_func = nn.MarginRankingLoss()\n",
        "  cost = loss_func(pos_dist,neg_dist)\n",
        "\n",
        "  return cost\n"
      ],
      "metadata": {
        "id": "ILfYFcLj2lqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_L1(real,pred):\n",
        "  return np.abs(real-pred)"
      ],
      "metadata": {
        "id": "d0rfUJronr3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_L2(real,pred):\n",
        "  return (real-pred)**2"
      ],
      "metadata": {
        "id": "tlelaHAenrvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DQx2kWIytpBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wckaxU8rV1I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(s_batch))"
      ],
      "metadata": {
        "id": "vdlkHifFVao4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initiallization for new set of batch = T_batch\n",
        "\n",
        "epochs = 10\n",
        "t_batch = 0\n",
        "pos_dist = 0\n",
        "neg_dist = 0\n",
        "k = 0\n",
        "\n",
        "# loop, sample(h, l, t)에 대한 for문\n",
        "\n",
        "optimizer = optim.SGD([rel_norm,entity_norm], lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "\n",
        "  for batch_idx, s in enumerate(s_batch):\n",
        "\n",
        "    # sample corrupted triplets\n",
        "    s_corrupt = torch.Tensor([0])\n",
        "    corrupt_sample = 0\n",
        "\n",
        "    for i in range(len(s)):\n",
        "\n",
        "      corrupt_sample = sampling_corrupt(s[i])\n",
        "\n",
        "      temp_pos_dist = torch.Tensor([dist_L1(s[i][0]+ s[i][1], s[i][2])])\n",
        "      temp_neg_dist = torch.Tensor([dist_L1(corrupt_sample[0]+ corrupt_sample[1], corrupt_sample[2])])\n",
        "\n",
        "      if t_batch == 0:\n",
        "        pos_dist = temp_pos_dist\n",
        "        neg_dist = temp_neg_dist\n",
        "\n",
        "      else:\n",
        "        pos_dist = torch.cat((pos_dist,temp_pos_dist))\n",
        "        print(pos_dist)\n",
        "        neg_dist = torch.cat((neg_dist,temp_neg_dist))\n",
        "        \n",
        "      t_batch += 1\n",
        "\n",
        "    for p in range(len(pos_dist)):\n",
        "      # optimizer.zero_grad()\n",
        "      cost = margin_loss(pos_dist[p], neg_dist[p])\n",
        "      cost.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{epochs}, Batch {batch_idx}/{batch_num}, Cost: {cost}\")\n",
        "\n",
        "\n",
        "    k += 1\n",
        "    if k > 6:\n",
        "      break \n"
      ],
      "metadata": {
        "id": "bM84Gt1DswEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader # for mini-batch sampling\n",
        "\n",
        "# loop 시작\n",
        "\n",
        "epochs = 10\n",
        "batch_num  = 100 # batch size\n",
        "s_batch = 0\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "\n",
        "  # sample (h,l,t) mini batch for mini-batch - SGD = S_batch\n",
        "\n",
        "  s_batch = DataLoader(\n",
        "      train,\n",
        "      batch_size = batch_num,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  # initiallization for new set of batch = T_batch\n",
        "  t_batch = 0\n",
        "  # cat positive & negative sample\n",
        "  mix_samples(s_batch)\n",
        "    \n",
        "# end\n"
      ],
      "metadata": {
        "id": "TL1dauNK2lYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update cost function\n",
        "    \n",
        "pos_dist = dist_L1()\n",
        "neg_dist = dist_L1()\n",
        "\n",
        "cost = margin_loss(pos_dist, neg_dist)\n",
        "\n",
        "print(f\"Epoch {epoch}/{epochs}, Batch {batch_idx}/{batch_num}, Cost: {cost}\")"
      ],
      "metadata": {
        "id": "F4pudk2A2liB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = nn.Embedding(5,3)\n",
        "a.weight"
      ],
      "metadata": {
        "id": "0RYYYRhegY2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.weight.data"
      ],
      "metadata": {
        "id": "yC3lIFq_h-pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a(torch.LongTensor([1]))"
      ],
      "metadata": {
        "id": "LBzGypqDgdvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.init.uniform_(a.weight.data, a= - 1, b= 1)"
      ],
      "metadata": {
        "id": "RUqd7i1P6iI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Triplets:\n",
        "#   def __init__(self, sample):\n",
        "#     self.head = sample[0]\n",
        "#     self.rel = sample[1]\n",
        "#     self.tail = sample[2]"
      ],
      "metadata": {
        "id": "YD1556il7Rch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}