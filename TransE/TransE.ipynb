{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransE",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install dgl-cu111 -f https://data.dgl.ai/wheels/repo.html"
      ],
      "metadata": {
        "id": "04wtC45f6pFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a077134d-448b-43c9-80e5-b0c46a6af865"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Requirement already satisfied: dgl-cu111 in /usr/local/lib/python3.7/dist-packages (0.7.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.6.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "dIPqtpI-UEQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a74a9d-401c-477d-fb03-e4cf611d8f5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_tensor = torch.Tensor([0,1])\n",
        "\n",
        "# https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.device\n",
        "# 어느 장치(cpu 혹은 gpu)에 텐서를 올릴지 지정합니다.\n",
        "# 아래는 torch.device라는 함수를 사용해 gpu로 장치를 지정합니다. \n",
        "device = torch.device('cuda')\n",
        "\n",
        "# https://pytorch.org/docs/stable/cuda.html?highlight=available#torch.cuda.is_available\n",
        "# gpu가 사용 가능한지 확인해줍니다.\n",
        "if torch.cuda.is_available():\n",
        "  \n",
        "  # https://pytorch.org/docs/stable/tensors.html?highlight=#torch.Tensor.to\n",
        "  # cpu에 있었던 텐서를 to 함수를 이용해 지정해놓은 장치(여기서는 gpu)로 올려줍니다.\n",
        "  gpu_tensor = cpu_tensor.to(device)\n",
        "  print(gpu_tensor)\n",
        "\n",
        "\n",
        "# to(device) 붙이면 gpu 연산 가능"
      ],
      "metadata": {
        "id": "hHfnbUebT80C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5110f72-5632-4e7c-b297-febceb632404"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oHBoEiB62jF9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data load\n",
        "\n",
        "import dgl\n",
        "from dgl.data import FB15kDataset\n",
        "import torch\n",
        "\n",
        "dataset = FB15kDataset()\n",
        "graph = dataset[0]\n",
        "\n",
        "# edata = returns a dict[str, Tensor]\n",
        "\n",
        "train_mask = graph.edata['train_mask']\n",
        "val_mask = graph.edata['val_mask']\n",
        "test_mask = graph.edata['test_mask']\n",
        "\n",
        "head, tail = graph.edges('uv')\n",
        "rel = graph.edata['etype']\n",
        "triplet = torch.stack([head, rel, tail], dim=1)\n",
        "\n",
        "train = triplet[train_mask]\n",
        "val = triplet[val_mask]\n",
        "test = triplet[test_mask]"
      ],
      "metadata": {
        "id": "tmhsrxhA2koc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd616eb-f531-4e51-c37d-807e6e877563"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# entities: 14951\n",
            "# relations: 1345\n",
            "# training edges: 483142\n",
            "# validation edges: 50000\n",
            "# testing edges: 59071\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "YpjJIcTfNh1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransE(nn.Module):\n",
        "\n",
        "  def __init__(self,num_entity, num_rel ,embed_dim, margin):\n",
        "    super(TransE, self).__init__()\n",
        "\n",
        "    bound = 6 / (embed_dim ** 0.5)\n",
        "\n",
        "    self.embed_dim = embed_dim\n",
        "    self.margin = margin\n",
        "\n",
        "    # entity initialize\n",
        "    self.entity_embed = nn.Embedding(num_entity, embed_dim)\n",
        "    self.entity_embed.weight.data = torch.nn.init.uniform_(self.entity_embed.weight.data, a= - bound, b= bound)\n",
        "    self.entity_embed.weight.data = F.normalize(self.entity_embed.weight.data,p=2.0, dim=1, eps=1e-12)\n",
        "\n",
        "    # relation initialize\n",
        "    self.rel_embed = nn.Embedding(num_rel, embed_dim)\n",
        "    self.rel_embed.weight.data = torch.nn.init.uniform_(self.rel_embed.weight.data, a= - bound, b= bound)\n",
        "    self.rel_embed.weight.data = F.normalize(self.rel_embed.weight.data,p=2.0, dim=1, eps=1e-12)\n",
        "    \n",
        "\n",
        "  def forward(self, batch, c_batch): # c_batch = corrupted batch\n",
        "    batch = batch.to(device)\n",
        "    c_batch = c_batch.to(device)\n",
        "    \n",
        "    head, rel, tail = batch[0], batch[1], batch[2]\n",
        "    c_head, c_tail = c_batch[0], c_batch[2] # c_ = corrupted\n",
        "\n",
        "    # positive sample\n",
        "    h = self.entity_embed(head).to(device)\n",
        "    r = self.rel_embed(rel).to(device)\n",
        "    t = self.entity_embed(tail).to(device)\n",
        "\n",
        "    # negative (= corrupted) sample\n",
        "    c_h = self.entity_embed(c_head).to(device)\n",
        "    c_t = self.entity_embed(c_tail).to(device)\n",
        "\n",
        "    # L1_dist: np.abs(real-pred) / L2_dist = (real-pred)**2\n",
        "    # use L1_dist\n",
        "    pos_dist = torch.norm(h+r - t, 2, dim = 0).to(device)\n",
        "    neg_dist = torch.norm(c_h+r - c_t, 2, dim = 0).to(device)\n",
        "    \n",
        "    return pos_dist, neg_dist"
      ],
      "metadata": {
        "id": "45Hi2LXNZb46"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main"
      ],
      "metadata": {
        "id": "ypl7D4VjNd2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# sampling corrupt function\n",
        "\n",
        "def sampling_corrupt(sample):\n",
        "  \n",
        "  temp_sample = sample.clone().detach() # not change original sample data\n",
        "\n",
        "  if random.random() > 0.5:\n",
        "\n",
        "    while(1):\n",
        "      \n",
        "      corrupt_head = random.choice(head)\n",
        "      if sample[0] != corrupt_head:\n",
        "        temp_sample[0] = corrupt_head\n",
        "        return temp_sample\n",
        "        break\n",
        "      \n",
        "  else:\n",
        "    while(1):\n",
        "      corrupt_tail = random.choice(tail)\n",
        "      if sample[2] != corrupt_tail:\n",
        "        temp_sample[2] = corrupt_tail\n",
        "        return temp_sample\n",
        "        break\n",
        "\n",
        "entity = graph.nodes()\n",
        "\n",
        "model = TransE(num_entity = len(entity), num_rel = len(rel), embed_dim = 50, margin = 0.5)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# for mini-batch sampling\n",
        "from torch.utils.data import DataLoader\n",
        "batch_size = 4800\n",
        "\n",
        "s_batch = DataLoader(\n",
        "    train,\n",
        "    batch_size = batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "\n",
        "  for batch_idx, s in enumerate(s_batch):\n",
        "      start = time.time()\n",
        "      s.to(device)\n",
        "\n",
        "      # sample corrupted triplets\n",
        "      corrupeted_sample = 0\n",
        "      corrupted_batch = []\n",
        "     \n",
        "      for i in range(len(s)):\n",
        "        corrupted_sample = sampling_corrupt(s[i])\n",
        "        corrupted_batch.append(corrupted_sample)\n",
        "\n",
        "      # reshape for triplet form\n",
        "      corrupted_batch = torch.stack(corrupted_batch)\n",
        "      corrupted_batch = corrupted_batch.reshape(-1,3)\n",
        "      corrupted_batch.to(device)\n",
        "      \n",
        "      pos_dist_group = []\n",
        "      neg_dist_group = []\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      for i in range(len(s)):\n",
        "        pos_dist, neg_dist = model(s[i], corrupted_batch[i])\n",
        "        pos_dist_group.append(pos_dist)\n",
        "        neg_dist_group.append(neg_dist)\n",
        "\n",
        "      pos_dist_group = torch.stack(pos_dist_group)\n",
        "      neg_dist_group = torch.stack(neg_dist_group)\n",
        "\n",
        "      loss_func = nn.MarginRankingLoss(margin = 0.5) # margin rank = max(0,−y∗(x1−x2)+margin)\n",
        "      loss = loss_func(pos_dist_group, neg_dist_group,torch.ones_like(pos_dist_group)*-1)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      end = time.time()\n",
        "      collapsed = end - start\n",
        "      print(f\"collapsed time: {collapsed}\")\n",
        "      print(f\"Epoch {epoch}/{epochs}, Batch {batch_idx}/{len(s_batch)}, Loss: {loss}\")\n",
        "  \n",
        "\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKpznA53_p9j",
        "outputId": "4053f687-9e29-4840-f49a-0187dda432a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collapsed time: 21.128891229629517\n",
            "Epoch 0/10, Batch 0/202, Loss: 0.5000765323638916\n",
            "collapsed time: 21.123464107513428\n",
            "Epoch 0/10, Batch 1/202, Loss: 0.4978112280368805\n",
            "collapsed time: 21.030547618865967\n",
            "Epoch 0/10, Batch 2/202, Loss: 0.49844759702682495\n",
            "collapsed time: 21.08294987678528\n",
            "Epoch 0/10, Batch 3/202, Loss: 0.5015605688095093\n",
            "collapsed time: 21.09828472137451\n",
            "Epoch 0/10, Batch 4/202, Loss: 0.49757757782936096\n",
            "collapsed time: 21.020882606506348\n",
            "Epoch 0/10, Batch 5/202, Loss: 0.5013521909713745\n",
            "collapsed time: 21.09777855873108\n",
            "Epoch 0/10, Batch 6/202, Loss: 0.5002166032791138\n",
            "collapsed time: 21.107596158981323\n",
            "Epoch 0/10, Batch 7/202, Loss: 0.5007187724113464\n",
            "collapsed time: 21.061738967895508\n",
            "Epoch 0/10, Batch 8/202, Loss: 0.5005778670310974\n",
            "collapsed time: 21.098220109939575\n",
            "Epoch 0/10, Batch 9/202, Loss: 0.5003821849822998\n",
            "collapsed time: 21.056906700134277\n",
            "Epoch 0/10, Batch 10/202, Loss: 0.5039043426513672\n",
            "collapsed time: 21.02669334411621\n",
            "Epoch 0/10, Batch 11/202, Loss: 0.4994737505912781\n",
            "collapsed time: 21.10341501235962\n",
            "Epoch 0/10, Batch 12/202, Loss: 0.5045281052589417\n",
            "collapsed time: 21.05514430999756\n",
            "Epoch 0/10, Batch 13/202, Loss: 0.5028801560401917\n",
            "collapsed time: 21.043779134750366\n",
            "Epoch 0/10, Batch 14/202, Loss: 0.4989725947380066\n",
            "collapsed time: 21.130000114440918\n",
            "Epoch 0/10, Batch 15/202, Loss: 0.5025873184204102\n",
            "collapsed time: 21.00089120864868\n",
            "Epoch 0/10, Batch 16/202, Loss: 0.5040716528892517\n",
            "collapsed time: 21.086285829544067\n",
            "Epoch 0/10, Batch 17/202, Loss: 0.4958958625793457\n",
            "collapsed time: 21.095112800598145\n",
            "Epoch 0/10, Batch 18/202, Loss: 0.5005061626434326\n",
            "collapsed time: 21.00545072555542\n",
            "Epoch 0/10, Batch 19/202, Loss: 0.500912606716156\n",
            "collapsed time: 21.094791650772095\n",
            "Epoch 0/10, Batch 20/202, Loss: 0.4994147717952728\n",
            "collapsed time: 21.09791374206543\n",
            "Epoch 0/10, Batch 21/202, Loss: 0.49817657470703125\n",
            "collapsed time: 21.071261167526245\n",
            "Epoch 0/10, Batch 22/202, Loss: 0.49736472964286804\n",
            "collapsed time: 21.09241032600403\n",
            "Epoch 0/10, Batch 23/202, Loss: 0.49666693806648254\n",
            "collapsed time: 21.09408473968506\n",
            "Epoch 0/10, Batch 24/202, Loss: 0.49998465180397034\n",
            "collapsed time: 21.012534856796265\n",
            "Epoch 0/10, Batch 25/202, Loss: 0.49795350432395935\n",
            "collapsed time: 21.09172010421753\n",
            "Epoch 0/10, Batch 26/202, Loss: 0.5001888871192932\n",
            "collapsed time: 21.128852367401123\n",
            "Epoch 0/10, Batch 27/202, Loss: 0.49596935510635376\n",
            "collapsed time: 21.012553453445435\n",
            "Epoch 0/10, Batch 28/202, Loss: 0.4982869625091553\n",
            "collapsed time: 21.09156823158264\n",
            "Epoch 0/10, Batch 29/202, Loss: 0.5006144642829895\n",
            "collapsed time: 21.140884399414062\n",
            "Epoch 0/10, Batch 30/202, Loss: 0.4954625964164734\n",
            "collapsed time: 21.012099266052246\n",
            "Epoch 0/10, Batch 31/202, Loss: 0.5048969388008118\n",
            "collapsed time: 21.087191343307495\n",
            "Epoch 0/10, Batch 32/202, Loss: 0.5042996406555176\n",
            "collapsed time: 21.094212532043457\n",
            "Epoch 0/10, Batch 33/202, Loss: 0.50068598985672\n",
            "collapsed time: 21.012258768081665\n",
            "Epoch 0/10, Batch 34/202, Loss: 0.5000061392784119\n",
            "collapsed time: 21.102543592453003\n",
            "Epoch 0/10, Batch 35/202, Loss: 0.5034425258636475\n",
            "collapsed time: 21.145533084869385\n",
            "Epoch 0/10, Batch 36/202, Loss: 0.5031642317771912\n",
            "collapsed time: 21.005409240722656\n",
            "Epoch 0/10, Batch 37/202, Loss: 0.5012928247451782\n",
            "collapsed time: 21.085734844207764\n",
            "Epoch 0/10, Batch 38/202, Loss: 0.49884167313575745\n",
            "collapsed time: 21.10411763191223\n",
            "Epoch 0/10, Batch 39/202, Loss: 0.49906811118125916\n",
            "collapsed time: 21.002883195877075\n",
            "Epoch 0/10, Batch 40/202, Loss: 0.4992135763168335\n",
            "collapsed time: 21.080726385116577\n",
            "Epoch 0/10, Batch 41/202, Loss: 0.49938660860061646\n",
            "collapsed time: 21.03478479385376\n",
            "Epoch 0/10, Batch 42/202, Loss: 0.4958127439022064\n",
            "collapsed time: 21.015957593917847\n",
            "Epoch 0/10, Batch 43/202, Loss: 0.5015497207641602\n",
            "collapsed time: 21.097231149673462\n",
            "Epoch 0/10, Batch 44/202, Loss: 0.5029368996620178\n",
            "collapsed time: 20.99657368659973\n",
            "Epoch 0/10, Batch 45/202, Loss: 0.4992653429508209\n",
            "collapsed time: 21.02998685836792\n",
            "Epoch 0/10, Batch 46/202, Loss: 0.5018373727798462\n",
            "collapsed time: 21.099852323532104\n",
            "Epoch 0/10, Batch 47/202, Loss: 0.4981793463230133\n",
            "collapsed time: 21.003302097320557\n",
            "Epoch 0/10, Batch 48/202, Loss: 0.4952572286128998\n",
            "collapsed time: 21.074125289916992\n",
            "Epoch 0/10, Batch 49/202, Loss: 0.5006837844848633\n",
            "collapsed time: 21.098385334014893\n",
            "Epoch 0/10, Batch 50/202, Loss: 0.5028695464134216\n",
            "collapsed time: 21.035199403762817\n",
            "Epoch 0/10, Batch 51/202, Loss: 0.49979400634765625\n",
            "collapsed time: 21.088435411453247\n",
            "Epoch 0/10, Batch 52/202, Loss: 0.5024746656417847\n",
            "collapsed time: 21.090234756469727\n",
            "Epoch 0/10, Batch 53/202, Loss: 0.5025804042816162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = []\n",
        "len(a)"
      ],
      "metadata": {
        "id": "06qkLDXBzBhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "# input1 = torch.Tensor([[1,2,3],[7,8,9]])\n",
        "# input2 = torch.Tensor([[4,5,6],[10,11,12]])\n",
        "\n",
        "input1 = torch.Tensor([1,2,3])\n",
        "input2 = torch.Tensor([[4,5,6]])\n",
        "\n",
        "print(input1)\n",
        "\n",
        "input1 = [np.array(input1)]\n",
        "\n",
        "print(input1)\n",
        "\n",
        "input1 = torch.Tensor(input1)\n",
        "print(input1)\n",
        "output.append(input1)\n",
        "output.append(input2)\n",
        "\n",
        "print(output)\n",
        "\n",
        "result = torch.cat(output, dim=0)\n",
        "print(result)\n",
        "\n",
        "# for ch in range(in_channels):\n",
        "#     tensor = my_fn(input_batch[:,ch,:,:])   #transform from (64, 1, 224, 224) to (64, 32, 224, 224)\n",
        "#     outputs.append(tensor)\n",
        "# result = torch.cat(outputs, dim=1)  #shape (64, 32*in_channels, 224, 224"
      ],
      "metadata": {
        "id": "SZyY51IebrG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [torch.Tensor([0]),torch.Tensor([1]),torch.Tensor([3])]\n",
        "b = torch.stack(a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "KfK23hEHLNVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.numel(torch.Tensor([0]))"
      ],
      "metadata": {
        "id": "UJxZjWZzJuI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for corrupt sample\n",
        "k = 0\n",
        "\n",
        "for batch_idx, s in enumerate(s_batch):\n",
        "  \n",
        "    corrupted = torch.Tensor([0])\n",
        "    # sample corrupted triplets\n",
        "    corrupt_sample = 0\n",
        "    print(f\"우씨: {s}\")\n",
        "\n",
        "    for i in range(len(s)):\n",
        "      corrupt_sample = sampling_corrupt(s[i])\n",
        "      if torch.numel(corrupted) == 1: #corrupted = tensor([0])\n",
        "        corrupted = corrupt_sample\n",
        "      else:\n",
        "        corrupted = torch.cat((corrupted, corrupt_sample))\n",
        "      corrupted = corrupted.reshape(-1,3)\n",
        "      print(f\"아으: {corrupted}\")\n",
        "    \n",
        "    print(f\"완성: {corrupted}\")\n",
        "\n",
        "    k += 1 # for test\n",
        "    if k > 5:\n",
        "      break"
      ],
      "metadata": {
        "id": "E97kZWoaDzcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for corrupt sample\n",
        "k = 0\n",
        "\n",
        "for batch_idx, s in enumerate(s_batch):\n",
        "  \n",
        "    temp_list = []\n",
        "    corrupted = torch.Tensor([0])\n",
        "    # sample corrupted triplets\n",
        "    corrupt_sample = 0\n",
        "    # print(f\"우씨: {s}\")\n",
        "\n",
        "    for i in range(len(s)):\n",
        "      corrupt_sample = sampling_corrupt(s[i])\n",
        "      corrupted = corrupt_sample\n",
        "      temp_list.append(corrupted)\n",
        "      \n",
        "\n",
        "      # print(f\"아으: {corrupted}\")\n",
        "    \n",
        "    # print(f\"완성: {corrupted}\")\n",
        "    print(temp_list)\n",
        "    output = torch.cat(temp_list, dim = 0)\n",
        "    print(output)\n",
        "    k += 1 # for test\n",
        "    if k > 5:\n",
        "      break"
      ],
      "metadata": {
        "id": "NlG4XsdegOJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "WV7wmrT9EDzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.arange(10).float()\n",
        "b = torch.arange(1, 11).float()"
      ],
      "metadata": {
        "id": "nXPt3RzjS3qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad = True\n",
        "b.requires_grad = True"
      ],
      "metadata": {
        "id": "xOdwyCNZS7C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # embedding initialize & normalization function\n",
        "\n",
        "# def uniform_initialize(val, bound):\n",
        "#       val = torch.nn.init.uniform_(torch.empty(val.shape), a= - bound, b= bound)\n",
        "#       return val\n",
        "\n",
        "# def normalization(val):\n",
        "#   temp_val = torch.Tensor([0])\n",
        "#   for v in val:\n",
        "#     norm_v = torch.Tensor([torch.norm(v)])\n",
        "#     temp_val = torch.cat((temp_val,norm_v))\n",
        "\n",
        "#   val = temp_val[1:] # 초기화 한 값 제거\n",
        "#   return val"
      ],
      "metadata": {
        "id": "oQvgdzUobpYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling corrupt function\n",
        "\n",
        "def sampling_corrupt(sample):\n",
        "  \n",
        "  temp_sample = sample.clone().detach() # not change original sample data\n",
        "\n",
        "  if random.random() > 0.5:\n",
        "\n",
        "    while(1):\n",
        "      \n",
        "      corrupt_head = random.choice(head)\n",
        "      if sample[0] != corrupt_head:\n",
        "        temp_sample[0] = corrupt_head\n",
        "        return temp_sample\n",
        "        break\n",
        "      \n",
        "  else:\n",
        "    while(1):\n",
        "      corrupt_tail = random.choice(tail)\n",
        "      if sample[2] != corrupt_tail:\n",
        "        temp_sample[2] = corrupt_tail\n",
        "        return temp_sample\n",
        "        break"
      ],
      "metadata": {
        "id": "9MmU20QhFntr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 시간이 너무 오래걸림, 모르는 함수가 있는건가 ?!\n",
        "\n",
        "# # relation set uniform으로 초기화 및 정규화, entity 초기화\n",
        "\n",
        "# k = 50 # embedding dimension\n",
        "\n",
        "# bound = 6/np.sqrt(k)\n",
        "\n",
        "# entity = graph.nodes()\n",
        "\n",
        "# # initialization rel, entity\n",
        "\n",
        "# rel_norm = uniform_initialize(rel, bound)\n",
        "# entity_norm = uniform_initialize(entity, bound)\n",
        "\n",
        "# # relation & entity normalization\n",
        "\n",
        "# rel_norm = normalization(rel_norm)\n",
        "# entity_norm = normalization(entity_norm)"
      ],
      "metadata": {
        "id": "7gaKuyLH2k6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def margin_loss(pos_dist, neg_dist):\n",
        "  \n",
        "  loss_func = nn.MarginRankingLoss()\n",
        "  cost = loss_func(pos_dist,neg_dist)\n",
        "\n",
        "  return cost\n"
      ],
      "metadata": {
        "id": "ILfYFcLj2lqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_L1(real,pred):\n",
        "  return np.abs(real-pred)"
      ],
      "metadata": {
        "id": "d0rfUJronr3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_L2(real,pred):\n",
        "  return (real-pred)**2"
      ],
      "metadata": {
        "id": "tlelaHAenrvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DQx2kWIytpBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wckaxU8rV1I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(s_batch))"
      ],
      "metadata": {
        "id": "vdlkHifFVao4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initiallization for new set of batch = T_batch\n",
        "\n",
        "epochs = 10\n",
        "t_batch = 0\n",
        "pos_dist = 0\n",
        "neg_dist = 0\n",
        "k = 0\n",
        "\n",
        "# loop, sample(h, l, t)에 대한 for문\n",
        "\n",
        "optimizer = optim.SGD([rel_norm,entity_norm], lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "\n",
        "  for batch_idx, s in enumerate(s_batch):\n",
        "\n",
        "    # sample corrupted triplets\n",
        "    s_corrupt = torch.Tensor([0])\n",
        "    corrupt_sample = 0\n",
        "\n",
        "    for i in range(len(s)):\n",
        "\n",
        "      corrupt_sample = sampling_corrupt(s[i])\n",
        "\n",
        "      temp_pos_dist = torch.Tensor([dist_L1(s[i][0]+ s[i][1], s[i][2])])\n",
        "      temp_neg_dist = torch.Tensor([dist_L1(corrupt_sample[0]+ corrupt_sample[1], corrupt_sample[2])])\n",
        "\n",
        "      if t_batch == 0:\n",
        "        pos_dist = temp_pos_dist\n",
        "        neg_dist = temp_neg_dist\n",
        "\n",
        "      else:\n",
        "        pos_dist = torch.cat((pos_dist,temp_pos_dist))\n",
        "        print(pos_dist)\n",
        "        neg_dist = torch.cat((neg_dist,temp_neg_dist))\n",
        "        \n",
        "      t_batch += 1\n",
        "\n",
        "    for p in range(len(pos_dist)):\n",
        "      # optimizer.zero_grad()\n",
        "      cost = margin_loss(pos_dist[p], neg_dist[p])\n",
        "      cost.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{epochs}, Batch {batch_idx}/{batch_num}, Cost: {cost}\")\n",
        "\n",
        "\n",
        "    k += 1\n",
        "    if k > 6:\n",
        "      break \n"
      ],
      "metadata": {
        "id": "bM84Gt1DswEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader # for mini-batch sampling\n",
        "\n",
        "# loop 시작\n",
        "\n",
        "epochs = 10\n",
        "batch_num  = 100 # batch size\n",
        "s_batch = 0\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "\n",
        "  # sample (h,l,t) mini batch for mini-batch - SGD = S_batch\n",
        "\n",
        "  s_batch = DataLoader(\n",
        "      train,\n",
        "      batch_size = batch_num,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  # initiallization for new set of batch = T_batch\n",
        "  t_batch = 0\n",
        "  # cat positive & negative sample\n",
        "  mix_samples(s_batch)\n",
        "    \n",
        "# end\n"
      ],
      "metadata": {
        "id": "TL1dauNK2lYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update cost function\n",
        "    \n",
        "pos_dist = dist_L1()\n",
        "neg_dist = dist_L1()\n",
        "\n",
        "cost = margin_loss(pos_dist, neg_dist)\n",
        "\n",
        "print(f\"Epoch {epoch}/{epochs}, Batch {batch_idx}/{batch_num}, Cost: {cost}\")"
      ],
      "metadata": {
        "id": "F4pudk2A2liB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종 버전"
      ],
      "metadata": {
        "id": "jYNBdqmclc6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = nn.Embedding(5,3)\n",
        "a.weight"
      ],
      "metadata": {
        "id": "0RYYYRhegY2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.weight.data"
      ],
      "metadata": {
        "id": "yC3lIFq_h-pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a(torch.LongTensor([1]))"
      ],
      "metadata": {
        "id": "LBzGypqDgdvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.init.uniform_(a.weight.data, a= - 1, b= 1)"
      ],
      "metadata": {
        "id": "RUqd7i1P6iI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Triplets:\n",
        "#   def __init__(self, sample):\n",
        "#     self.head = sample[0]\n",
        "#     self.rel = sample[1]\n",
        "#     self.tail = sample[2]"
      ],
      "metadata": {
        "id": "YD1556il7Rch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
